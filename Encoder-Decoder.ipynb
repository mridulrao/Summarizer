{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc693850",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "\n",
    "for i in range(1, 511):\n",
    "    if i < 10:\n",
    "        i = '00' + str(i)\n",
    "    elif i > 9 and i < 100:\n",
    "        i = '0' + str(i)\n",
    "    else:\n",
    "        i = str(i)\n",
    "        \n",
    "    news_article = 'BBC_News_Summary/News_Articles/business/' + i + '.txt'\n",
    "    news = ''\n",
    "    with open(news_article) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            news += line\n",
    "            news += \" \"\n",
    "        article_list.append(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f9a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = []\n",
    "\n",
    "for i in range(1, 511):\n",
    "    if i < 10:\n",
    "        i = '00' + str(i)\n",
    "    elif i > 9 and i < 100:\n",
    "        i = '0' + str(i)\n",
    "    else:\n",
    "        i = str(i)\n",
    "        \n",
    "    news_article_summary = 'BBC_News_Summary/Summaries/business/' + i + '.txt'\n",
    "    summary = '_START_ '\n",
    "    \n",
    "    with open(news_article_summary) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            summary += line\n",
    "            summary += \" \"\n",
    "        summary = summary + \" _END_\"\n",
    "        summary_list.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989da6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>_START_ TimeWarner said fourth quarter sales r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>_START_ The dollar has hit its highest level a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>_START_ Yukos' owner Menatep Group says it wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>_START_ Rod Eddington, BA's chief executive, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>_START_ Pernod has reduced the debt it took on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "1  Dollar gains on Greenspan speech  The dollar h...   \n",
       "2  Yukos unit buyer faces loan claim  The owners ...   \n",
       "3  High fuel prices hit BA's profits  British Air...   \n",
       "4  Pernod takeover talk lifts Domecq  Shares in U...   \n",
       "\n",
       "                                             summary  \n",
       "0  _START_ TimeWarner said fourth quarter sales r...  \n",
       "1  _START_ The dollar has hit its highest level a...  \n",
       "2  _START_ Yukos' owner Menatep Group says it wil...  \n",
       "3  _START_ Rod Eddington, BA's chief executive, s...  \n",
       "4  _START_ Pernod has reduced the debt it took on...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = ['article', 'summary'])\n",
    "\n",
    "for i in range(len(article_list)):\n",
    "    row = pd.Series({'article' : article_list[i], 'summary' : summary_list[i]})\n",
    "    df = pd.concat([df, row.to_frame().T], ignore_index = True)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7348a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "article_tr, article_val, summary_tr, summary_val=train_test_split(df['article'],\n",
    "                                                                   df['summary'],\n",
    "                                                                   test_size=0.1,\n",
    "                                                                   random_state=0,\n",
    "                                                                   shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edff00f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "articles = list(df['article'])\n",
    "\n",
    "for article in articles:\n",
    "    if len(article.split()) > max_length:\n",
    "        max_length = len(article.split())\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01680c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "summaries = list(df['summary'])\n",
    "\n",
    "for summary in summaries:\n",
    "    if len(summary.split()) > max_length:\n",
    "        max_length = len(summary.split())\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d07d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12675\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "article_tokenizer = Tokenizer()\n",
    "article_tokenizer.fit_on_texts(list(df['article']))\n",
    "\n",
    "article_tr = article_tokenizer.texts_to_sequences(article_tr) \n",
    "article_val = article_tokenizer.texts_to_sequences(article_val) \n",
    "\n",
    "article_tr = pad_sequences(article_tr,  maxlen = 800, padding='post') \n",
    "article_val = pad_sequences(article_val, maxlen = 800, padding='post')\n",
    "\n",
    "article_voc_size = len(article_tokenizer.word_index) +1\n",
    "\n",
    "print(article_voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a409628d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8202\n"
     ]
    }
   ],
   "source": [
    "summary_tokenizer = Tokenizer()\n",
    "summary_tokenizer.fit_on_texts(list(df['summary']))\n",
    "\n",
    "summary_tr = summary_tokenizer.texts_to_sequences(summary_tr) \n",
    "summary_val = summary_tokenizer.texts_to_sequences(summary_val) \n",
    "\n",
    "summary_tr = pad_sequences(summary_tr,  maxlen = 350, padding='post') \n",
    "summary_val = pad_sequences(summary_val, maxlen = 350, padding='post')\n",
    "\n",
    "summary_voc_size = len(summary_tokenizer.word_index) +1\n",
    "\n",
    "print(summary_voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8dbf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.layers import Concatenate, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1c907934",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_inputs = Input(shape=(800), name = 'Encoder_Input') #max length of article\n",
    "embedding = Embedding(12675, 3, trainable=True, name = 'Encoder_Embedding')(embedding_inputs) #vocab_size_article, neurons\n",
    "\n",
    "encoder_layer_1 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_1') #neurons \n",
    "encoder_output_1, state_h1, state_c1 = encoder_layer_1(embedding)\n",
    "\n",
    "encoder_layer_2 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_2') #neurons \n",
    "encoder_output_2, state_h2, state_c2 = encoder_layer_2(encoder_output_1)\n",
    "\n",
    "encoder_layer_3 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_3') #neurons \n",
    "encoder_output_3, state_h3, state_c3 = encoder_layer_3(encoder_output_2)\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name = 'Decoder_Input')\n",
    "decoder_embedding_layer = Embedding(8202, 50, trainable=True, name = 'Decoder_Embedding')#vocab_size_summary, neurons\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs) \n",
    "\n",
    "decoder_layer_1 = LSTM(32, return_sequences = True, return_state = True, name = 'Decoder_LSTM')\n",
    "decoder_output_1, decoder_state_h1, decoder_state_c1 = decoder_layer_1(decoder_embedding, \n",
    "                                                                       initial_state=[state_h3, state_c3])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(8202, activation = 'softmax'))#vocab_size_summary\n",
    "decoder_outputs = decoder_dense(decoder_output_1)\n",
    "\n",
    "model = Model([embedding_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "134f01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853d5ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  16,    1, 1227, ...,    0,    0,    0],\n",
       "       [  16,   21,    1, ...,    0,    0,    0],\n",
       "       [  16, 1936,  286, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  16,    8,    1, ...,    0,    0,    0],\n",
       "       [  16,    1,  514, ...,    0,    0,    0],\n",
       "       [  16, 1986,    6, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tr[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78ee6a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0202acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "09559795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 16s 1s/step - loss: 8.7587 - val_loss: 8.1126\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 12s 972ms/step - loss: 7.7452 - val_loss: 7.3418\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 7.0530 - val_loss: 6.7282\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 6.4662 - val_loss: 6.1843\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 5.9412 - val_loss: 5.6878\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 15s 1s/step - loss: 5.4639 - val_loss: 5.2406\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 5.0328 - val_loss: 4.8342\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 4.6429 - val_loss: 4.4714\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 12s 996ms/step - loss: 4.2992 - val_loss: 4.1637\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 4.0225 - val_loss: 3.9349\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 3.8261 - val_loss: 3.7855\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 3.6675 - val_loss: 3.5877\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 3.4875 - val_loss: 3.4485\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 3.3605 - val_loss: 3.3525\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 3.2672 - val_loss: 3.2711\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 12s 965ms/step - loss: 3.1931 - val_loss: 3.2118\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 3.1326 - val_loss: 3.1639\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 12s 978ms/step - loss: 3.0830 - val_loss: 3.1256\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 12s 993ms/step - loss: 3.0428 - val_loss: 3.0986\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 3.0098 - val_loss: 3.0758\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.9833 - val_loss: 3.0595\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.9616 - val_loss: 3.0482\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.9439 - val_loss: 3.0402\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 12s 990ms/step - loss: 2.9289 - val_loss: 3.0349\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.9163 - val_loss: 3.0318\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 12s 999ms/step - loss: 2.9053 - val_loss: 3.0292\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.8955 - val_loss: 3.0297\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8872 - val_loss: 3.0285\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8790 - val_loss: 3.0289\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8720 - val_loss: 3.0298\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 12s 991ms/step - loss: 2.8651 - val_loss: 3.0320\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.8585 - val_loss: 3.0322\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.8524 - val_loss: 3.0352\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.8467 - val_loss: 3.0364\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.8410 - val_loss: 3.0376\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8358 - val_loss: 3.0387\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8305 - val_loss: 3.0398\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8254 - val_loss: 3.0422\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8202 - val_loss: 3.0429\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8155 - val_loss: 3.0446\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8105 - val_loss: 3.0447\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8059 - val_loss: 3.0461\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.8012 - val_loss: 3.0471\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7965 - val_loss: 3.0480\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7918 - val_loss: 3.0493\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7873 - val_loss: 3.0499\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7824 - val_loss: 3.0511\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7780 - val_loss: 3.0514\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7738 - val_loss: 3.0519\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7690 - val_loss: 3.0521\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.7649 - val_loss: 3.0563\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7604 - val_loss: 3.0545\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7560 - val_loss: 3.0542\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7514 - val_loss: 3.0543\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7472 - val_loss: 3.0549\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7428 - val_loss: 3.0544\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7386 - val_loss: 3.0551\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7343 - val_loss: 3.0570\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7299 - val_loss: 3.0551\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7254 - val_loss: 3.0565\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7211 - val_loss: 3.0559\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7169 - val_loss: 3.0555\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.7125 - val_loss: 3.0547\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7079 - val_loss: 3.0558\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.7045 - val_loss: 3.0548\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6999 - val_loss: 3.0550\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6949 - val_loss: 3.0566\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6910 - val_loss: 3.0562\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.6867 - val_loss: 3.0557\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6819 - val_loss: 3.0578\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6784 - val_loss: 3.0556\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6718 - val_loss: 3.0557\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6692 - val_loss: 3.0560\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6644 - val_loss: 3.0548\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.6594 - val_loss: 3.0553\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6554 - val_loss: 3.0537\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6496 - val_loss: 3.0543\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6457 - val_loss: 3.0557\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6414 - val_loss: 3.0539\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.6368 - val_loss: 3.0526\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.6311 - val_loss: 3.0535\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.6275 - val_loss: 3.0531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.6239 - val_loss: 3.0527\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.6185 - val_loss: 3.0523\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.6134 - val_loss: 3.0532\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.6092 - val_loss: 3.0510\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.6042 - val_loss: 3.0560\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.6011 - val_loss: 3.0514\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5942 - val_loss: 3.0522\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.5914 - val_loss: 3.0498\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5869 - val_loss: 3.0483\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5806 - val_loss: 3.0500\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5773 - val_loss: 3.0500\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.5728 - val_loss: 3.0497\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.5682 - val_loss: 3.0492\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.5625 - val_loss: 3.0486\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5595 - val_loss: 3.0491\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5544 - val_loss: 3.0477\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5495 - val_loss: 3.0470\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5456 - val_loss: 3.0487\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5407 - val_loss: 3.0471\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5387 - val_loss: 3.0449\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5325 - val_loss: 3.0465\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5267 - val_loss: 3.0469\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5231 - val_loss: 3.0455\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5191 - val_loss: 3.0449\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5138 - val_loss: 3.0463\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5095 - val_loss: 3.0456\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5054 - val_loss: 3.0447\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.5008 - val_loss: 3.0446\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4965 - val_loss: 3.0440\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4924 - val_loss: 3.0445\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4872 - val_loss: 3.0442\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4820 - val_loss: 3.0452\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4795 - val_loss: 3.0460\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4742 - val_loss: 3.0444\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4707 - val_loss: 3.0448\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4650 - val_loss: 3.0461\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4617 - val_loss: 3.0447\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4574 - val_loss: 3.0466\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4524 - val_loss: 3.0455\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4484 - val_loss: 3.0466\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4446 - val_loss: 3.0461\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4396 - val_loss: 3.0474\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4360 - val_loss: 3.0479\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4312 - val_loss: 3.0459\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4276 - val_loss: 3.0451\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4221 - val_loss: 3.0492\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4192 - val_loss: 3.0487\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4152 - val_loss: 3.0476\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4104 - val_loss: 3.0504\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4060 - val_loss: 3.0492\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.4028 - val_loss: 3.0498\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3971 - val_loss: 3.0548\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3944 - val_loss: 3.0501\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3903 - val_loss: 3.0509\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3856 - val_loss: 3.0495\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3816 - val_loss: 3.0529\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3779 - val_loss: 3.0506\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3741 - val_loss: 3.0520\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3698 - val_loss: 3.0538\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3652 - val_loss: 3.0547\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3625 - val_loss: 3.0572\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3569 - val_loss: 3.0555\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.3544 - val_loss: 3.0587\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.3498 - val_loss: 3.0568\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3467 - val_loss: 3.0589\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3422 - val_loss: 3.0567\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.3370 - val_loss: 3.0601\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3346 - val_loss: 3.0622\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3297 - val_loss: 3.0609\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3272 - val_loss: 3.0610\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3212 - val_loss: 3.0637\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.3199 - val_loss: 3.0640\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.3142 - val_loss: 3.0622\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3122 - val_loss: 3.0667\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3060 - val_loss: 3.0677\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3045 - val_loss: 3.0667\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.3010 - val_loss: 3.0665\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.2954 - val_loss: 3.0752\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.2929 - val_loss: 3.0725\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.2880 - val_loss: 3.0745\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2851 - val_loss: 3.0740\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 13s 1s/step - loss: 2.2812 - val_loss: 3.0742\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.2787 - val_loss: 3.0747\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2736 - val_loss: 3.0739\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2700 - val_loss: 3.0745\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2667 - val_loss: 3.0810\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.2632 - val_loss: 3.0758\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.2593 - val_loss: 3.0781\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2556 - val_loss: 3.0801\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2526 - val_loss: 3.0795\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2485 - val_loss: 3.0795\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.2441 - val_loss: 3.0819\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2419 - val_loss: 3.0823\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2382 - val_loss: 3.0852\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2339 - val_loss: 3.0860\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2321 - val_loss: 3.0784\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2268 - val_loss: 3.0867\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2234 - val_loss: 3.0872\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2207 - val_loss: 3.0877\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2166 - val_loss: 3.0869\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2135 - val_loss: 3.0894\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2096 - val_loss: 3.0897\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2060 - val_loss: 3.0897\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.2037 - val_loss: 3.0872\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1990 - val_loss: 3.0916\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1956 - val_loss: 3.0911\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1934 - val_loss: 3.0921\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1895 - val_loss: 3.0912\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1861 - val_loss: 3.0945\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1822 - val_loss: 3.0926\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1784 - val_loss: 3.0925\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1757 - val_loss: 3.1015\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1734 - val_loss: 3.0987\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1687 - val_loss: 3.0971\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1662 - val_loss: 3.0928\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.1623 - val_loss: 3.0999\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1585 - val_loss: 3.0965\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 12s 1s/step - loss: 2.1559 - val_loss: 3.1003\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([article_tr, summary_tr[:,:-1]], \n",
    "                    summary_tr.reshape(summary_tr.shape[0], summary_tr.shape[1], 1)[:,1:],\n",
    "                    epochs=200,\n",
    "                    validation_split = 0.2,\n",
    "                    batch_size=32,\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "24c9b1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f479316",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index = summary_tokenizer.index_word \n",
    "reverse_source_word_index = article_tokenizer.index_word \n",
    "target_word_index = summary_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "53092968",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=embedding_inputs, outputs=[encoder_output_3, state_h3, state_c3])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(32,))\n",
    "decoder_state_input_c = Input(shape=(32,))\n",
    "decoder_hidden_state_input = Input(shape=(800, 32))\n",
    "\n",
    "dec_emb2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_layer_1(dec_emb2, \n",
    "                                                       initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    inputs = [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "    outputs = [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a103b947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "e_out, e_h, e_c = encoder_model.predict(article_tr[5].reshape(1, 800))\n",
    "output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2c6be769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.72192513e-03, -2.65722983e-02,  4.68563521e-03, ...,\n",
       "          9.72672552e-03, -3.48326676e-02,  5.18781971e-03],\n",
       "        [ 5.04894741e-03, -6.14997223e-02, -1.00747729e-03, ...,\n",
       "          2.64351983e-02, -9.26559344e-02,  3.33030485e-02],\n",
       "        [ 6.92221220e-04, -1.11993216e-01, -2.29806434e-02, ...,\n",
       "          5.50499111e-02, -2.06687719e-01,  9.82135460e-02],\n",
       "        ...,\n",
       "        [-1.97674875e-04, -1.08240247e-02, -9.70864177e-01, ...,\n",
       "          5.14688551e-01, -9.99468744e-01,  9.95865464e-01],\n",
       "        [-1.97674875e-04, -1.08240098e-02, -9.70864177e-01, ...,\n",
       "          5.14688730e-01, -9.99468744e-01,  9.95865464e-01],\n",
       "        [-1.97675472e-04, -1.08240042e-02, -9.70864236e-01, ...,\n",
       "          5.14688969e-01, -9.99468744e-01,  9.95865643e-01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1db85c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.3276100e-07, 2.7229390e-01, 1.1834061e-03, ...,\n",
       "         1.2312859e-07, 6.4808391e-06, 2.1447604e-09]]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0f5dbc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[16.]]\n",
      "[[[1.3276100e-07 2.7229390e-01 1.1834061e-03 ... 1.2312859e-07\n",
      "   6.4808391e-06 2.1447604e-09]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq = np.zeros((1,1))\n",
    "print(target_seq)\n",
    "target_seq[0, 0] = target_word_index['start']\n",
    "print(target_seq)\n",
    "\n",
    "print(output_tokens)\n",
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "reverse_target_word_index[sampled_token_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bc222e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8202,)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens[0, -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8bb89075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_array = np.array([1, 0, 3, 4])\n",
    "sample_array.shape\n",
    "np.argmax(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "83a8b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    \n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        print([target_seq])\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (350-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbe45d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:      \n",
    "        if((i != 0 and i != target_word_index['start']) and i != target_word_index['end']):\n",
    "            newString = newString + reverse_target_word_index[i]+' '\n",
    "            \n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString = newString + reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fdfca77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pernod takeover talk lifts Domecq  Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.  Reports in the Wall Street Journal and the Financial Times suggested that the French spirits firm is considering a bid, but has yet to contact its target. Allied Domecq shares in London rose 4% by 1200 GMT, while Pernod shares in Paris slipped 1.2%. Pernod said it was seeking acquisitions but refused to comment on specifics.  Pernod's last major purchase was a third of US giant Seagram in 2000, the move which propelled it into the global top three of drinks firms. The other two-thirds of Seagram was bought by market leader Diageo. In terms of market value, Pernod - at 7.5bn euros ($9.7bn) - is about 9% smaller than Allied Domecq, which has a capitalisation of £5.7bn ($10.7bn; 8.2bn euros). Last year Pernod tried to buy Glenmorangie, one of Scotland's premier whisky firms, but lost out to luxury goods firm LVMH. Pernod is home to brands including Chivas Regal Scotch whisky, Havana Club rum and Jacob's Creek wine. Allied Domecq's big names include Malibu rum, Courvoisier brandy, Stolichnaya vodka and Ballantine's whisky - as well as snack food chains such as Dunkin' Donuts and Baskin-Robbins ice cream. The WSJ said that the two were ripe for consolidation, having each dealt with problematic parts of their portfolio. Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains. \n"
     ]
    }
   ],
   "source": [
    "print(article_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d770884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_START_ Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.Pernod said it was seeking acquisitions but refused to comment on specifics.In terms of market value, Pernod - at 7.5bn euros ($9.7bn) - is about 9% smaller than Allied Domecq, which has a capitalisation of £5.7bn ($10.7bn; 8.2bn euros).Allied Domecq shares in London rose 4% by 1200 GMT, while Pernod shares in Paris slipped 1.2%.  _END_\n"
     ]
    }
   ],
   "source": [
    "print(summary_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a88dee5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "[array([[16.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[19.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[44.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[34.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[26.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[34.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[7.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[13.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[26.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[8.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[19.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[90.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[135.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[634.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[array([[186.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[49.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[7.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[13.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[18.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[49.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1521.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[4.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[634.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[186.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[49.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[7.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[10.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[13.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[18.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[186.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[1.]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "[array([[1521.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[4.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[830.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1270.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[156.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[156.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[331.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[3.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[19.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[90.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[634.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[684.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[24.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[1521.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[4.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[541.]])]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[156.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[156.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1060.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[array([[634.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[134.]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[331.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[4.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[156.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1060.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[634.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[300.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[634.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[684.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[24.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[1521.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[4.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[7.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[10.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[13.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1521.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[4.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[1060.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[25.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[634.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[684.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[24.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[296.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[1.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[1521.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[4.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[7.]])]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[array([[10.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[13.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[9.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[39.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[2.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[array([[200.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[5.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[46.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[152.]])]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[array([[6.]])]\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" the us economy has been to be to be to be to be than a year has been to be to be to be to be to be than a new executive and said it has been to a year for a new executive and the us group has been to take a ebbers to be made to be able to a new executive and told the company said it was to take a new executive and the company has been to take the new executive and the university of the ebbers has been to be to be able to a new executive and told the company said that it was to take a new executive and told the university of the company's venture and the ebbers has been to a ebbers to fund a fund a new bid to fund a fund a new bid to fund a new fund to be a glazer in a fund a new fund the us group has has been to take to be to be to be to be to be to be able to take a new and vehicles and mr ebbers has been to take a new executive and the university of the ebbers has been to give a ebbers to fund a fund a new bid to fund a new fund a new bid to be used to be a fund to be able to a new offer and a glazer of a new bid to be used to be to be able to take a new and fund to be to be to be to be able to take a new and vehicles and mr ebbers has been to take a new executive and the university of said that it has been to take a new executive and the university of the ebbers has been to be to be used to be to be able to take a new and vehicles and mr ebbers has been to take a new executive and the university of said that it has been to take a new executive and the\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(article_tr[4].reshape(1, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5411a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
