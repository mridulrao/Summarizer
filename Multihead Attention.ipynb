{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769e59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, MultiHeadAttention, Dense\n",
    "from tensorflow.keras.layers import Concatenate, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "375b8939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Encoder_Input (InputLayer)  [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " Encoder_Embedding (Embeddi  (None, 32, 32)               32768     ['Encoder_Input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " LSTM_1 (LSTM)               [(None, 32, 32),             8320      ['Encoder_Embedding[0][0]']   \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32)]                                                         \n",
      "                                                                                                  \n",
      " Decoder_Input (InputLayer)  [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " LSTM_2 (LSTM)               [(None, 32, 32),             8320      ['LSTM_1[0][0]']              \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32)]                                                         \n",
      "                                                                                                  \n",
      " Decoder_Embedding (Embeddi  (None, None, 32)             32768     ['Decoder_Input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " LSTM_3 (LSTM)               [(None, 32, 32),             8320      ['LSTM_2[0][0]']              \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32)]                                                         \n",
      "                                                                                                  \n",
      " Decoder_LSTM (LSTM)         [(None, None, 32),           8320      ['Decoder_Embedding[0][0]',   \n",
      "                              (None, 32),                            'LSTM_3[0][1]',              \n",
      "                              (None, 32)]                            'LSTM_3[0][2]']              \n",
      "                                                                                                  \n",
      " Attention (MultiHeadAttent  ((None, 32, 32),             556       ['LSTM_3[0][0]',              \n",
      " ion)                         (None, 2, 32, None))                   'Decoder_LSTM[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 32, 64)               0         ['Decoder_LSTM[0][0]',        \n",
      " )                                                                   'Attention[0][0]']           \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDi  (None, 32, 1024)             66560     ['concatenate_6[0][0]']       \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 165932 (648.17 KB)\n",
      "Trainable params: 100396 (392.17 KB)\n",
      "Non-trainable params: 65536 (256.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_inputs = Input(shape=(32), name = 'Encoder_Input') #max length of sentence\n",
    "embedding = Embedding(1024, 32, trainable=False, name = 'Encoder_Embedding')(embedding_inputs) #vocab_size_article, neurons\n",
    "\n",
    "encoder_layer_1 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_1') #neurons \n",
    "encoder_output_1, state_h1, state_c1 = encoder_layer_1(embedding)\n",
    "\n",
    "encoder_layer_2 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_2') #neurons \n",
    "encoder_output_2, state_h2, state_c2 = encoder_layer_2(encoder_output_1)\n",
    "\n",
    "encoder_layer_3 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_3') #neurons \n",
    "encoder_output_3, state_h3, state_c3 = encoder_layer_3(encoder_output_2)\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name = 'Decoder_Input')\n",
    "decoder_embedding = Embedding(1024, 32, trainable=False, name = 'Decoder_Embedding')(decoder_inputs)#vocab_size_summary, neurons\n",
    "\n",
    "decoder_layer_1 = LSTM(32, return_sequences = True, return_state = True, name = 'Decoder_LSTM')\n",
    "decoder_output_1, decoder_state_h1, decoder_state_c1 = decoder_layer_1(decoder_embedding, \n",
    "                                                                       initial_state=[state_h3, state_c3])\n",
    "\n",
    "attention_layer = MultiHeadAttention(num_heads = 2, key_dim = 2, name = 'Attention')\n",
    "attn_out, attn_state = attention_layer(encoder_output_3, decoder_output_1, return_attention_scores = True)\n",
    "\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_output_1, attn_out])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(1024, activation = 'softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "model = Model([embedding_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce4a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
