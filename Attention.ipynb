{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047ccd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "\n",
    "for i in range(1, 511):\n",
    "    if i < 10:\n",
    "        i = '00' + str(i)\n",
    "    elif i > 9 and i < 100:\n",
    "        i = '0' + str(i)\n",
    "    else:\n",
    "        i = str(i)\n",
    "        \n",
    "    news_article = 'BBC_News_Summary/News_Articles/business/' + i + '.txt'\n",
    "    news = ''\n",
    "    with open(news_article) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            news += line\n",
    "            news += \" \"\n",
    "        article_list.append(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741f7a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jobs growth still slow in the US  The US created fewer jobs than expected in January, but a fall in jobseekers pushed the unemployment rate to its lowest level in three years.  According to Labor Department figures, US firms added only 146,000 jobs in January. The gain in non-farm payrolls was below market expectations of 190,000 new jobs. Nevertheless it was enough to push down the unemployment rate to 5.2%, its lowest level since September 2001. The job gains mean that President Bush can celebrate - albeit by a very fine margin - a net growth in jobs in the US economy in his first term in office. He presided over a net fall in jobs up to last November\\'s Presidential election - the first President to do so since Herbert Hoover. As a result, job creation became a key issue in last year\\'s election. However, when adding December and January\\'s figures, the administration\\'s first term jobs record ended in positive territory.  The Labor Department also said it had revised down the jobs gains in December 2004, from 157,000 to 133,000.  Analysts said the growth in new jobs was not as strong as could be expected given the favourable economic conditions. \"It suggests that employment is continuing to expand at a moderate pace,\" said Rick Egelton, deputy chief economist at BMO Financial Group. \"We are not getting the boost to employment that we would have got given the low value of the dollar and the still relatively low interest rate environment.\" \"The economy is producing a moderate but not a satisfying amount of job growth,\" said Ken Mayland, president of ClearView Economics. \"That means there are a limited number of new opportunities for workers.\" '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5064b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = []\n",
    "\n",
    "for i in range(1, 511):\n",
    "    if i < 10:\n",
    "        i = '00' + str(i)\n",
    "    elif i > 9 and i < 100:\n",
    "        i = '0' + str(i)\n",
    "    else:\n",
    "        i = str(i)\n",
    "        \n",
    "    news_article_summary = 'BBC_News_Summary/Summaries/business/' + i + '.txt'\n",
    "    summary = '_START_ '\n",
    "    \n",
    "    with open(news_article_summary) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            summary += line\n",
    "            summary += \" \"\n",
    "        summary = summary + \" _END_\"\n",
    "        summary_list.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0156b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_START_ The job gains mean that President Bush can celebrate - albeit by a very fine margin - a net growth in jobs in the US economy in his first term in office.Analysts said the growth in new jobs was not as strong as could be expected given the favourable economic conditions.The Labor Department also said it had revised down the jobs gains in December 2004, from 157,000 to 133,000.The US created fewer jobs than expected in January, but a fall in jobseekers pushed the unemployment rate to its lowest level in three years.\"The economy is producing a moderate but not a satisfying amount of job growth,\" said Ken Mayland, president of ClearView Economics.He presided over a net fall in jobs up to last November\\'s Presidential election - the first President to do so since Herbert Hoover.  _END_'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551266f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>_START_ TimeWarner said fourth quarter sales r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>_START_ The dollar has hit its highest level a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>_START_ Yukos' owner Menatep Group says it wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>_START_ Rod Eddington, BA's chief executive, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>_START_ Pernod has reduced the debt it took on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "1  Dollar gains on Greenspan speech  The dollar h...   \n",
       "2  Yukos unit buyer faces loan claim  The owners ...   \n",
       "3  High fuel prices hit BA's profits  British Air...   \n",
       "4  Pernod takeover talk lifts Domecq  Shares in U...   \n",
       "\n",
       "                                             summary  \n",
       "0  _START_ TimeWarner said fourth quarter sales r...  \n",
       "1  _START_ The dollar has hit its highest level a...  \n",
       "2  _START_ Yukos' owner Menatep Group says it wil...  \n",
       "3  _START_ Rod Eddington, BA's chief executive, s...  \n",
       "4  _START_ Pernod has reduced the debt it took on...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = ['article', 'summary'])\n",
    "\n",
    "for i in range(len(article_list)):\n",
    "    row = pd.Series({'article' : article_list[i], 'summary' : summary_list[i]})\n",
    "    df = pd.concat([df, row.to_frame().T], ignore_index = True)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9393002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "article_tr, article_val, summary_tr, summary_val=train_test_split(df['article'],\n",
    "                                                                   df['summary'],\n",
    "                                                                   test_size=0.1,\n",
    "                                                                   random_state=0,\n",
    "                                                                   shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3269f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "articles = list(df['article'])\n",
    "\n",
    "for article in articles:\n",
    "    if len(article.split()) > max_length:\n",
    "        max_length = len(article.split())\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e283a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "summaries = list(df['summary'])\n",
    "\n",
    "for summary in summaries:\n",
    "    if len(summary.split()) > max_length:\n",
    "        max_length = len(summary.split())\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c500d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12675\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "article_tokenizer = Tokenizer()\n",
    "article_tokenizer.fit_on_texts(list(df['article']))\n",
    "\n",
    "article_tr = article_tokenizer.texts_to_sequences(article_tr) \n",
    "article_val = article_tokenizer.texts_to_sequences(article_val) \n",
    "\n",
    "article_tr = pad_sequences(article_tr,  maxlen = 800, padding='post') \n",
    "article_val = pad_sequences(article_val, maxlen = 800, padding='post')\n",
    "\n",
    "article_voc_size = len(article_tokenizer.word_index) +1\n",
    "\n",
    "print(article_voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c035b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8202\n"
     ]
    }
   ],
   "source": [
    "summary_tokenizer = Tokenizer()\n",
    "summary_tokenizer.fit_on_texts(list(df['summary']))\n",
    "\n",
    "summary_tr = summary_tokenizer.texts_to_sequences(summary_tr) \n",
    "summary_val = summary_tokenizer.texts_to_sequences(summary_val) \n",
    "\n",
    "summary_tr = pad_sequences(summary_tr,  maxlen = 350, padding='post') \n",
    "summary_val = pad_sequences(summary_val, maxlen = 350, padding='post')\n",
    "\n",
    "summary_voc_size = len(summary_tokenizer.word_index) +1\n",
    "\n",
    "print(summary_voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14ce55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Attention, Normalization, Dense\n",
    "from tensorflow.keras.layers import Concatenate, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93bdec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Encoder_Input (InputLayer)  [(None, 800)]                0         []                            \n",
      "                                                                                                  \n",
      " Encoder_Embedding (Embeddi  (None, 800, 3)               38025     ['Encoder_Input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " LSTM_1 (LSTM)               [(None, 800, 32),            4608      ['Encoder_Embedding[0][0]']   \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32)]                                                         \n",
      "                                                                                                  \n",
      " Decoder_Input (InputLayer)  [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " LSTM_2 (LSTM)               [(None, 800, 32),            8320      ['LSTM_1[0][0]']              \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32)]                                                         \n",
      "                                                                                                  \n",
      " Decoder_Embedding (Embeddi  (None, None, 50)             410100    ['Decoder_Input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " LSTM_3 (LSTM)               [(None, 800, 32),            8320      ['LSTM_2[0][0]']              \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32)]                                                         \n",
      "                                                                                                  \n",
      " Decoder_LSTM (LSTM)         [(None, None, 32),           10624     ['Decoder_Embedding[0][0]',   \n",
      "                              (None, 32),                            'LSTM_3[0][1]',              \n",
      "                              (None, 32)]                            'LSTM_3[0][2]']              \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     ((None, 800, 32),            0         ['LSTM_3[0][0]',              \n",
      "                              (None, 800, None))                     'Decoder_LSTM[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, None, 32)             0         ['Decoder_LSTM[0][0]',        \n",
      " )                                                                   'attention_4[0][0]']         \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDi  (None, None, 8202)           270666    ['concatenate_4[0][0]']       \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 750663 (2.86 MB)\n",
      "Trainable params: 750663 (2.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_inputs = Input(shape=(800), name = 'Encoder_Input') #max length of article\n",
    "embedding = Embedding(12675, 3, trainable=True, name = 'Encoder_Embedding')(embedding_inputs) #vocab_size_article, neurons\n",
    "\n",
    "encoder_layer_1 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_1') #neurons \n",
    "encoder_output_1, state_h1, state_c1 = encoder_layer_1(embedding)\n",
    "\n",
    "encoder_layer_2 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_2') #neurons \n",
    "encoder_output_2, state_h2, state_c2 = encoder_layer_2(encoder_output_1)\n",
    "\n",
    "encoder_layer_3 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_3') #neurons \n",
    "encoder_output_3, state_h3, state_c3 = encoder_layer_3(encoder_output_2)\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name = 'Decoder_Input')\n",
    "decoder_embedding = Embedding(8202, 50, trainable=True, name = 'Decoder_Embedding')(decoder_inputs)#vocab_size_summary, neurons\n",
    "\n",
    "decoder_layer_1 = LSTM(32, return_sequences = True, return_state = True, name = 'Decoder_LSTM')\n",
    "decoder_output_1, decoder_state_h1, decoder_state_c1 = decoder_layer_1(decoder_embedding, \n",
    "                                                                       initial_state=[state_h3, state_c3])\n",
    "\n",
    "attention_layer = Attention()\n",
    "attn_out, attn_state = attention_layer([encoder_output_3, decoder_output_1], return_attention_scores = True)\n",
    "\n",
    "\n",
    "decoder_concat = Concatenate(axis=1)([decoder_output_1, attn_out])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(8202, activation = 'softmax'))#vocab_size_summary\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "model = Model([embedding_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5349e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2f5cac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459, 349, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = summary_tr.reshape(summary_tr.shape[0], summary_tr.shape[1], 1)[:,1:]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c4a39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459, 349)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tr[:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b767c5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459, 800)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc05bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 14:47:01.903728: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/f4/4mwvrr4x2dg6l94x0rks7ypr0000gn/T/ipykernel_15880/2468508544.py\", line 1, in <module>\n      history = model.fit([article_tr, summary_tr[:,:-1]],\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [36768,8202] and labels shape [11168]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_43921]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marticle_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_tr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msummary_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/f4/4mwvrr4x2dg6l94x0rks7ypr0000gn/T/ipykernel_15880/2468508544.py\", line 1, in <module>\n      history = model.fit([article_tr, summary_tr[:,:-1]],\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/Users/kawaii/opt/miniconda3/envs/m1_no_gpu/lib/python3.8/site-packages/keras/src/backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [36768,8202] and labels shape [11168]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_43921]"
     ]
    }
   ],
   "source": [
    "history = model.fit([article_tr, summary_tr[:,:-1]], \n",
    "                    summary_tr.reshape(summary_tr.shape[0], summary_tr.shape[1], 1)[:,1:],\n",
    "                    epochs=20,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660aec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_inputs = Input(shape=(800), name = 'Encoder_Input') #max length of article\n",
    "embedding = Embedding(12675, 3, trainable=True, name = 'Encoder_Embedding')(embedding_inputs) #vocab_size_article, neurons\n",
    "\n",
    "encoder_layer_1 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_1') #neurons \n",
    "encoder_output_1, state_h1, state_c1 = encoder_layer_1(embedding)\n",
    "\n",
    "encoder_layer_2 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_2') #neurons \n",
    "encoder_output_2, state_h2, state_c2 = encoder_layer_2(encoder_output_1)\n",
    "\n",
    "encoder_layer_3 = LSTM(32, return_sequences=True, return_state=True, name = 'LSTM_3') #neurons \n",
    "encoder_output_3, state_h3, state_c3 = encoder_layer_3(encoder_output_2)\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name = 'Decoder_Input')\n",
    "decoder_embedding = Embedding(8202, 50, trainable=True, name = 'Decoder_Embedding')(decoder_inputs)#vocab_size_summary, neurons\n",
    "\n",
    "decoder_layer_1 = LSTM(32, return_sequences = True, return_state = True, name = 'Decoder_LSTM')\n",
    "decoder_output_1, decoder_state_h1, decoder_state_c1 = decoder_layer_1(decoder_embedding, \n",
    "                                                                       initial_state=[state_h3, state_c3])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(8202, activation = 'softmax'))#vocab_size_summary\n",
    "decoder_outputs = decoder_dense(decoder_output_1)\n",
    "\n",
    "model = Model([embedding_inputs, decoder_inputs], decoder_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
